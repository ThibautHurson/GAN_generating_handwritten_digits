{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a67d88",
   "metadata": {},
   "source": [
    "# Generating MNIST handwritten digits with GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed9428",
   "metadata": {},
   "source": [
    "Generative Adversarial Network (GAN) is a class of machine learning frameworks introduced by Ian Goodfellow et al. in 2014. GANs are used for estimating generative models via an adversary process, in which we simultaneously train two models: A generative model G that capture the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake.\n",
    "\n",
    "GANs gained rapidly in popularity and have been used in a lot of applications such as:\n",
    "- Learning to generate realistic images given exemplary images\n",
    "- Learning to generate realistic music given exemplary recordings\n",
    "- Learning to generate realistic text given exemplary corpus\n",
    "\n",
    "We will focus here on implementing a Deep Convolutional Generative Adversarial Networks (DCGANs) for generating handwritten digits. The generator G will learn how to generate new plausible handwritten digits between 0 and 9, and the discriminator will estimate if images are from the dataset (\"Real\" images) or if they are new (\"Fake\" images).\n",
    "\n",
    "<img src=\"https://cdn-media-1.freecodecamp.org/images/m41LtQVUf3uk5IOYlHLpPazxI3pWDwG8VEvU\" alt=\"Alt text that describes the graphic\" title=\"Genrative Adversarial Network framework\" />\n",
    "\n",
    "https://medium.freecodecamp.org/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394\n",
    "\n",
    "In the case of image generation, the discriminator is a Convolutional Neural Network (CNN) that classify whether an image is real or generated, and the generator is made of inverse convolutional layers to transform a random input to an image.\n",
    "\n",
    "### Summary\n",
    "* [1. Data Preprocessing](#chapter1)\n",
    "* [2. GAN model](#chapter2)\n",
    "    * [a. The Discriminator model](#section_2_1)\n",
    "    * [b. The Generator model](#section_2_2)\n",
    "* [3. Training the model](#chapter3)\n",
    "* [4. Training the model](#chapter4)\n",
    "\n",
    "* [Useful Links](#links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3400f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2356fc721bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose \n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from timeit import default_timer as timer   \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ef16d",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "The MNIST dataset is composed of 70000 28x28 grayscale images of handwritten digits between 0 and 9, along with their respective label.\n",
    "\n",
    "The training set and the test set have respectively 60000 and 10000 images.\n",
    "\n",
    "Let's load the dataset using Keras mnist.load_data() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64b2108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (60000, 28, 28) (60000,)\n",
      "Test shape: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the mnist dataset\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "print('Train shape:', x_train.shape, y_train.shape)\n",
    "print('Test shape:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b826cc",
   "metadata": {},
   "source": [
    "We need to reshape images because images are 2D arrays and convolutional neural networks expect 3D arrays of images as input of the following shape: [width, heigth, channels].\n",
    "\n",
    "Here we only have one greyscale channel (if images where colored, there would be 3 channels for Red, Green, and Blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38730fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images\n",
    "x_train = x_train.reshape((x_train.shape[0],28,28,1))\n",
    "x_test = x_test.reshape((x_test.shape[0],28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff7acd",
   "metadata": {},
   "source": [
    "We must also rescale pixel values from the [0,255] range to the normalized range.\n",
    "Then, we plot several digit images from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f852128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "x_plot = np.squeeze(x_train)\n",
    "# Plot some image examples\n",
    "plt.figure(figsize=(10,10))\n",
    "i = 0\n",
    "for i in range (25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8212b28",
   "metadata": {},
   "source": [
    "## 2. GAN model <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "\n",
    "### a. The Discriminator model <a class=\"anchor\" id=\"section_2_1\"></a>\n",
    "First, we implement the discriminator model. It is a binary classifier that takes as input images and tells if they are real or fake. We use two convolutional layers with 64 filters each, a kernel size of (3,3) and a (2,2) strides. \n",
    "\n",
    "The convolutional layers are both followed by a dropout layer. Then, we add a fully connected layer of 64 nodes, followed by the output layer.\n",
    "\n",
    "We use LeakyReLU activation function for hidden layers, and use a sigmoid function at the output layer to get the probability that a sample is real or fake.\n",
    "\n",
    "The model is trained using bach normalization (except for the input layer), Adam optimizer and the binary crossentropy loss function as we are in a binary classification setting.\n",
    "\n",
    "Note: Directly applying batchnorm to all layers results in sample oscillation and model instability.\n",
    "\n",
    "Those parameters were chosen by following Radford et al. guidelines for implementing Deep Convolutional Generative Adversarial Networks (DCGANs). The link to the paper is provided below in [Useful Links](#links)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b21f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(image_shape=(28,28,1)):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(3,3), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(epsilon=1e-5, momentum=0.9))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.0002,beta_1=0.5),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = get_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d4b12",
   "metadata": {},
   "source": [
    "### b. The Generator model <a class=\"anchor\" id=\"section_2_2\"></a>\n",
    "\n",
    "As explained earlier, the generator aim is to create new images of  handwritten digits that the discriminator won't be able to differenciate from real handwritten digits.\n",
    "\n",
    "The generator takes as input a random vector drawn from a normal distribution, and upsample several times to obtain the output image. Here we chose to have a vector of size 100.\n",
    "\n",
    "The first layer of the generator is a Dense layer that has a number of nodes that will enable us by reshaping to obtain a low resolution of the output image. For example to get an image that is one quarter the size of the output image, we use 7x7 = 49 nodes.\n",
    "\n",
    "Now that we have a low resolution version of the output, we are going to upsample using transpose convolutional layers (Conv2DTranspose layers) with strides 2. Conv2DTranspose basically do the inverse of a normal Conv2D layer, and using strides of 2 will double the size of the image. Hence, by using 2 Conv2DTranspose layers with strides 2, we manage to quadruple the 7x7 image to obtain the 28*28 output image. We use model.summary() to verify that we upsample images properly. In particular we can see below that the output layer is of shape (28, 28, 1).\n",
    "\n",
    "Once again, we follow recommandations from Radford et al. and use ReLU activation in generator for all layers except for the output, which uses Tanh, and Batch Normalization after each Conv2DTranspose hidden layers.\n",
    "\n",
    "Note: As for the discriminator, directly applying batchnorm to all layers results in sample oscillation and model instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(random_vect_size):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Base image of shape 7x7\n",
    "    model.add(Dense(512*7*7, activation='relu', input_dim=random_vect_size))\n",
    "    model.add(Reshape((7, 7, 512)))\n",
    "    \n",
    "    # Upsample to 14x14\n",
    "    model.add(Conv2DTranspose(256, (4,4), strides=(2,2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(epsilon=1e-5, momentum=0.9))\n",
    "    \n",
    "    # Upsample to 28x28\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(epsilon=1e-5, momentum=0.9))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Conv2DTranspose(1, (7,7), activation='tanh', padding='same'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31fbf0c",
   "metadata": {},
   "source": [
    "One thing to notice here is that we do not compile the generator model yet. This will be done in [3. Training the model](#chapter2). We will explain how to use the discriminator to train the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e2ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vect_size = 100\n",
    "generator = get_generator(random_vect_size)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b2b8e",
   "metadata": {},
   "source": [
    "Let's define the function that will help us generating the random vector, and the function that will use the generator model to generate fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d515b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_vect(size, nb_samples):\n",
    "    vect = np.random.randn(nb_samples, size)\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12532e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fake_images(generator, random_vect_size, nb_samples):\n",
    "    rand_vect = get_random_vect(random_vect_size, nb_samples)\n",
    "    x_gen = generator.predict(rand_vect)\n",
    "    \n",
    "    # Create the label vector for these fake images\n",
    "    y_gen = np.zeros(nb_samples)\n",
    "    \n",
    "    return x_gen, y_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4701fcdf",
   "metadata": {},
   "source": [
    "Let's generate a few images and plot the result to verify that our implementation works well. We are supposed to obtain randomly generated greyscale images as our generator is not trained yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed616bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vect_size = 100\n",
    "nb_samples = 25\n",
    "\n",
    "generator = get_generator(random_vect_size)\n",
    "x_gen, _ = get_fake_images(generator, random_vect_size, nb_samples)\n",
    "x_gen = np.squeeze(x_gen)\n",
    "\n",
    "# Plot some image examples\n",
    "plt.figure(figsize=(10,10))\n",
    "i = 0\n",
    "for i in range (25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_gen[i], cmap=plt.cm.binary)\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb40b7",
   "metadata": {},
   "source": [
    "## 3. Training the model <a class=\"anchor\" id=\"chapter3\"></a>\n",
    "\n",
    "Training the GAN model will work as follow.\n",
    "\n",
    "We will use batches, and for each batch, we will first update the discriminator. Then, we will update the generator by using the discriminator to evaluate the performance of the generator.\n",
    "\n",
    "The idea is that the more the discriminator detects fake images, the more the generator is updated. At some point, the generator will perform well and the discriminator will no longer be able to distinguish fake images from true images.\n",
    "\n",
    "First, to train the generator, we will create a third model that will encapsulate both the generator and the discriminator as we need to use the discriminator as a measure of how well the generator is performing. \n",
    "\n",
    "The discriminator weights are not trained in this model as for each batch we first train the discriminator and then the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GAN(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.0002,beta_1=0.5),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = get_GAN(generator, discriminator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999dae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(generator, random_vect_size):\n",
    "    x_gen, _ = get_fake_images(generator, random_vect_size, 100)\n",
    "    x_gen = np.squeeze(x_gen)\n",
    "\n",
    "    # Plot some image examples\n",
    "    plt.figure(figsize=(10,10))\n",
    "    i = 0\n",
    "    for i in range (100):\n",
    "        plt.subplot(10,10,i+1)\n",
    "        plt.axis('off')\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x_gen[i], cmap=plt.cm.binary)\n",
    "        i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cca89c",
   "metadata": {},
   "source": [
    "We define the training procedure manually by iterating over an arbitrary number of epochs, and an arbitrary batch size. For each epoch and each batch, we generate real and fake samples, and we train the discriminator. Then, we generate random inputs for the generator with inverted labels. This is one of the key trick! We want the generator to beat the discrimintor. Thus, if the discriminator predicts that the generated images are real, then we don't update the generator, and conversely, if the discriminator predicts that generated images are fake, then we need to update the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, gan, x_train, random_vect_size, epochs=3, batch=128):\n",
    "    # Number of batches per epoch\n",
    "    ba_per_ep = int(x_train.shape[0]/batch)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        x_train = shuffle(x_train)\n",
    "        for j in range(ba_per_ep):\n",
    "            # generate real samples\n",
    "            x_real = x_train[batch*j: batch*(j+1)]\n",
    "            y_real = np.ones(x_real.shape[0])\n",
    "            # generate fake samples\n",
    "            x_fake, y_fake = get_fake_images(generator, random_vect_size, batch)            \n",
    "            # Stack real and fake samples, and shuffle\n",
    "            D_x_train, D_y_train = np.vstack((x_real, x_fake)), np.concatenate((y_real, y_fake))\n",
    "            # Update the discriminator\n",
    "            D_loss, _ = discriminator.train_on_batch(D_x_train, D_y_train)\n",
    "            \n",
    "            # Create the random inputs for the generator\n",
    "            x_gen = get_random_vect(random_vect_size, batch)\n",
    "            # Create inverted labels vector for these fake images that will be used to train the generator\n",
    "            y_gen = np.ones(batch)\n",
    "            # Update the generator\n",
    "            G_loss, _ = gan.train_on_batch(x_gen, y_gen)\n",
    "            G_loss, _ = gan.train_on_batch(x_gen, y_gen) #update twice to avoid the rapid convergence of the discriminator\n",
    "\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, ba_per_ep, D_loss, G_loss))\n",
    "        print('Epoch' + str(i) + ': ' + 'Gen loss ' + str(G_loss) + ', Dis loss ' + str(D_loss))\n",
    "        # save the generator model tile file\n",
    "        filename = 'generator_model_%03d.h5' % (i + 1)\n",
    "        generator.save(filename)\n",
    "        predict_and_plot(load_model(filename), random_vect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vect_size = 100\n",
    "\n",
    "start = timer()\n",
    "# train the model\n",
    "train(generator, discriminator, gan, x_train, random_vect_size, epochs=50,  batch=256)\n",
    "print(\"Training time:\", timer() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279e2cf",
   "metadata": {},
   "source": [
    "## 4. Results <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "\n",
    "Now that we trained the model and save it at each epoch, we can generate handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75979368",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb8e7aa4ba60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generator_model_020.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredict_and_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_vect_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "final_generator = load_model('generator_model_020.h5')\n",
    "\n",
    "predict_and_plot(final_generator, random_vect_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1535063",
   "metadata": {},
   "source": [
    "## Useful Links <a class=\"anchor\" id=\"links\"></a>\n",
    "\n",
    "**GAN original paper:**\n",
    "\n",
    "https://arxiv.org/abs/1406.2661\n",
    "\n",
    "GOODFELLOW, Ian J., POUGET-ABADIE, Jean, MIRZA, Mehdi, et al. Generative adversarial networks. arXiv preprint arXiv:1406.2661, 2014.\n",
    "\n",
    "**Tutorial for implementing a GAN for Generating MNIST Handwritten Digits:**\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/\n",
    "\n",
    "**Deep Convolutional Generative Adversarial Networks (DCGANs) paper:**\n",
    "https://arxiv.org/pdf/1511.06434.pdf\n",
    "\n",
    "Radford, A., Metz, L., & Chintala, S. (2015). Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
